{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and overview\n",
    "\n",
    "In this course, we will build on the techniques learnt in numerical analysis in CMIII and make some of the notions there more rigorous. \n",
    "\n",
    "In addition to thinking about discretising in time (ODEs) we will also look at discretising differential equations in space (PDEs), and the interplay between them.\n",
    "\n",
    "We'll start by recapitulating some of the terminology and results from CMIII, in particular stability and consistency of numerical methods for ODEs.\n",
    "\n",
    "Some of this material is taken from [Jed Brown's](https://jedbrown.org) numerical PDEs course https://github.com/cucs-numpde/numpde, licensed under BSD 2-clause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretising an ODE\n",
    "\n",
    "### Method of lines\n",
    "\n",
    "When we eventually encounter spatial derivatives, along with time derivatives, we will first discretise in space, obtaining a system of ODEs and then in time. This is known as the _method of lines_. For now, we will just assume that we have already discretised in space to obtain the ODE\n",
    "$$\n",
    " \\dot u = f(t, u).\n",
    "$$\n",
    "This is a _first order_ ODE, since there is only one time derivative.\n",
    "\n",
    "#### Second (and higher-order) ODEs\n",
    "\n",
    "An ODE with higher time derivatives, for example the second order problem\n",
    "$$\n",
    "\\ddot u = f(t, u, \\dot u)\n",
    "$$\n",
    "can always be converted into a system of first order problems by introducing auxiliary variables\n",
    "$$\n",
    "\\begin{align}\n",
    "u_0 &= u\\\\\n",
    "u_1 &= \\dot u\n",
    "\\end{align}\n",
    "$$\n",
    "so that we obtain\n",
    "$$\n",
    "\\begin{bmatrix} \\dot u_0 \\\\ \\dot u_1 \\end{bmatrix} = \\begin{bmatrix} u_1 \\\\ f(t, u_0, u_1) \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "We'll therefore focus on first-order systems.\n",
    "\n",
    "#### Uniqueness\n",
    "\n",
    "We will call $u^*(t)$ a _solution_ to $\\dot u = f(t, u)$, if, for all $t$\n",
    "\n",
    "$$\n",
    "\\dot u^*(t) = f(t, u^*(t)).\n",
    "$$\n",
    "\n",
    "We note, and are not the first, that this solution usually contains a free parameter, so that for uniqueness we need to specify an _initial value_ $u(0) = u_0$. Such problems are therefore termed _initial value problems_ or IVPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretising the $\\dot u$ term\n",
    "\n",
    "In CMIII, you mostly focussed on explicit (or forward) Euler to discretise the time derivative. This is a one-sided difference method, where we write:\n",
    "\n",
    "$$\n",
    "\\dot u = \\frac{u(t+\\Delta t) - u(t)}{\\Delta t} = f(t, u(t)),\n",
    "$$\n",
    "and so\n",
    "\n",
    "$$\n",
    "u(t+\\Delta t) = u(t) + \\Delta t f(t, u(t)).\n",
    "$$\n",
    "\n",
    "Let's look at how this behaves for a sample problem\n",
    "\n",
    "$$\n",
    "\\dot u = -k(u - \\cos{t})\n",
    "$$\n",
    "\n",
    "For an initial value $u(0) = u_0$, this problem has exact solution\n",
    "\n",
    "$$\n",
    "u(t) = \\frac{k}{1+k^2}(\\sin{t} + k \\cos{t}) + \\left(u_0 - \\frac{k^2}{1+k^2}\\right) \\exp{(-kt)}.\n",
    "$$\n",
    "\n",
    "Note that most real problems will not have such easy to compute solutions (hint: use an [integrating factor](https://en.wikipedia.org/wiki/Integrating_factor) and integrate by parts twice to compute the resulting integral).\n",
    "\n",
    "Let's go ahead and integrate this equation numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "pyplot.style.use(\"ggplot\")\n",
    "\n",
    "class f(object):\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "    \n",
    "    def __call__(self, t, u):\n",
    "        return -self.k * (u - numpy.cos(t))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"f(k={})\".format(self.k)\n",
    "\n",
    "    def exact(self, t, u_0):\n",
    "        k = self.k\n",
    "        k2p1 = k/(1 + k**2)\n",
    "        return (u_0 - k*k2p1)*numpy.exp(-k*t) + k2p1 * (numpy.sin(t) + k*numpy.cos(t))\n",
    "    \n",
    "def ode_euler(f, u_0, T, dt=0.1):\n",
    "    u = numpy.array(u_0)\n",
    "    t = 0\n",
    "    thist = [t]\n",
    "    uhist = [u_0]\n",
    "    while t < T:\n",
    "        dt = min(dt, T - t)\n",
    "        u += dt * f(t, u)\n",
    "        t += dt\n",
    "        thist.append(t)\n",
    "        uhist.append(u.copy())\n",
    "    return numpy.asarray(thist), numpy.asarray(uhist)\n",
    "\n",
    "u_0 = numpy.array(0.2)\n",
    "\n",
    "pyplot.figure()\n",
    "\n",
    "for k in [2, 10]:\n",
    "    rhs = f(k)\n",
    "    thist, uhist = ode_euler(rhs, u_0, dt=.1, T=12)\n",
    "    pyplot.plot(thist, uhist, \"o\", linestyle=\"solid\", label=str(rhs)+' Forward Euler')\n",
    "    pyplot.plot(thist, rhs.exact(thist, u_0), label=str(rhs)+' exact')\n",
    "pyplot.legend(bbox_to_anchor=(0.5, 1), loc='center', ncol=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good in the eyeball norm.\n",
    "\n",
    "#### Questions\n",
    "\n",
    "1. What happens when you increase $k$ further?\n",
    "2. What about if you try and increase $\\Delta t$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit Euler\n",
    "\n",
    "Rather than evaluating all the right hand side terms in our time discretisation _explicitly_, using already known values of $u$ at the beginning of the timestep, we can also evaluate them _implicitly_ using values at the end of the timestep. In that case, we end up with the discrete problem\n",
    "\n",
    "$$\n",
    "u(t + \\Delta t) - \\Delta t f(t + \\Delta t, u(t + \\Delta t)) = u(t).\n",
    "$$\n",
    "\n",
    "This is called _implicit_ (or backward) Euler. In the general case where $f$ is nonlinear, we must solve a nonlinear equation at this point. Let's skip over that for now and only consider the linear problem where we can write\n",
    "\n",
    "$$\n",
    "f(t, u) = Au\n",
    "$$\n",
    "for some matrix $A$.\n",
    "Rearranging, we obtain\n",
    "$$\n",
    "(I - \\Delta t A)u(t + \\Delta t) = u(t)\n",
    "$$\n",
    "and so a single step now requires us to invert the matrix $(I - \\Delta t A)$. This may be _significantly_ more expensive than just evaluating the right hand side (a matrix-vector product). So what does this buy us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact solution of linear problems\n",
    "\n",
    "The solution to the problem\n",
    "$$\n",
    "\\dot u = A u\n",
    "$$\n",
    "can be written using the [matrix exponential](https://en.wikipedia.org/wiki/Matrix_exponential) as\n",
    "$$\n",
    "u(t) = \\exp{(A t)}u(0)\n",
    "$$\n",
    "where the exponential is formally defined using the Taylor series\n",
    "$$\n",
    "\\exp{A} = \\sum_{n=0}^{\\infty} \\frac{A^{n}}{n!},\n",
    "$$\n",
    "and there are many (both good and bad) [ways to compute it](https://doi.org/10.1137/S00361445024180).\n",
    "\n",
    "If we can efficiently evaluate the matrix exponential, then we can directly compute the solution to our linear ODE at any time $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the behaviour of explict and implicit Euler on a test problem with purely oscillatory solutions. Choosing\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 0 & 1\\\\ -1 & 0 \\end{bmatrix}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "u_0 = \\begin{bmatrix} 0.75 \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "we expect\n",
    "$$\n",
    "u(t) = \\begin{bmatrix} 0.75 \\cos t\\\\-0.75 \\sin t\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Rather than laboriously working this out each time, we can compute an \"exact\" solution by explicitly computing the matrix exponential. [scipy](https://scipy.org) provides a builtin function to do this, `scipy.linalg.expm`.\n",
    "\n",
    "##### Question\n",
    "\n",
    "If scipy didn't provide this function, can you think of a fast way of computing matrix exponentials if the matrix $A$ is diagonalisable\n",
    "\n",
    "$$\n",
    "A = X \\Lambda X^{-1}.\n",
    "$$\n",
    "\n",
    "Hint, substitute the expansion into the power series and note that $X X^{-1} = \\mathbb{1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import expm\n",
    "\n",
    "class linear(object):\n",
    "    def __init__(self, A):\n",
    "        self.A = A.copy()\n",
    "    \n",
    "    def __call__(self, t, u):\n",
    "        return self.A @ u\n",
    "    \n",
    "    def exact(self, t, u_0):\n",
    "        t = numpy.array(t, ndmin=1)\n",
    "        return [numpy.real_if_close(expm(self.A*s) @ u_0) for s in t]\n",
    "\n",
    "test = linear(numpy.array([[0, 1],\n",
    "                           [-1, 0]]))\n",
    "u_0 = numpy.array([.75, 0])\n",
    "thist, uhist = ode_euler(test, u_0, dt=.1, T=15)\n",
    "pyplot.figure()\n",
    "pyplot.plot(thist, uhist, '.', label='Euler')\n",
    "pyplot.plot(thist, test.exact(thist, u_0), label='exact')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.title('Forward Euler');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at backward Euler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_beuler(A, u_0, T, dt=0.1):\n",
    "    u = numpy.array(u_0)\n",
    "    t = 0\n",
    "    thist = [t]\n",
    "    uhist = [u_0]\n",
    "    while t < T:\n",
    "        dt = min(dt, T - t)\n",
    "        # u <- (I - dt A)^{-1} u\n",
    "        u = numpy.linalg.solve(numpy.eye(len(A)) - dt*A, u)\n",
    "        t += dt\n",
    "        thist.append(t)\n",
    "        uhist.append(u.copy())\n",
    "    return numpy.asarray(thist), numpy.asarray(uhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = linear(numpy.array([[0, 1],\n",
    "                           [-1, 0]]))\n",
    "u_0 = numpy.array([.75, 0])\n",
    "thist, uhist = ode_beuler(test.A, u_0, dt=.1, T=15)\n",
    "pyplot.figure()\n",
    "pyplot.plot(thist, uhist, '.', label='Euler')\n",
    "pyplot.plot(thist, test.exact(thist, u_0), label='exact')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.title('Backward Euler');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The (implicit) midpoint method\n",
    "\n",
    "Already for this simple problem neither forward nor backward Euler produce particularly accurate results unless we choose tiny timesteps. These are not the only choices we can make. We could instead evaluate the right hand side $f$ at the midpoint of the timestep\n",
    "\n",
    "$$\n",
    "u(t + \\Delta t) = u(t) + \\Delta t f\\left(t + \\Delta t/2, \\frac{u(t) + u(t + \\Delta t)}{2}\\right).\n",
    "$$\n",
    "\n",
    "Which for linear problems reduces to\n",
    "\n",
    "$$\n",
    "\\left(I - \\frac{\\Delta t}{2}\\right)u(t + \\Delta t) = \\left(I + \\frac{\\Delta t}{2}\\right)u(t)\n",
    "$$\n",
    "again requiring a solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_midpoint(A, u_0, T, dt=0.1):\n",
    "    u = numpy.array(u_0)\n",
    "    t = 0\n",
    "    thist = [t]\n",
    "    uhist = [u_0]\n",
    "    I = numpy.eye(len(A))\n",
    "    while t < T:\n",
    "        dt = min(dt, T - t)\n",
    "        # u <- (I - dt/2 A)^{-1} (I + dt/2 A) u\n",
    "        u = numpy.linalg.solve(I - dt/2*A, (I + dt/2*A) @ u)\n",
    "        t += dt\n",
    "        thist.append(t)\n",
    "        uhist.append(u.copy())\n",
    "    return numpy.asarray(thist), numpy.asarray(uhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = linear(numpy.array([[0, 1],\n",
    "                           [-1, 0]]))\n",
    "u_0 = numpy.array([.75, 0])\n",
    "thist, uhist = ode_midpoint(test.A, u_0, dt=.1, T=15)\n",
    "pyplot.figure()\n",
    "pyplot.plot(thist, uhist, '.', label='Midpoint')\n",
    "pyplot.plot(thist, test.exact(thist, u_0), label='exact')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.title('Implicit Midpoint');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much more accurate!\n",
    "\n",
    "## Linear stability\n",
    "\n",
    "To assess the stability of time integration schemes, we consider their behaviour when applied to the linear test question (called the _Dahlquist test equation_)\n",
    "\n",
    "$$\n",
    "\\dot u = \\lambda u\n",
    "$$\n",
    "where $\\lambda \\in \\mathbb{C}$ is some complex number. When taking a step of length $\\Delta t$ This equation has exact solution\n",
    "$$\n",
    "u(\\Delta t) = u_0 \\exp{(\\lambda \\Delta t)} = u_0 \\exp{(\\operatorname{Re} \\lambda \\Delta t)} (\\cos \\operatorname{Im} \\lambda \\Delta t) + i\\sin\\operatorname{Im}\\lambda \\Delta t).\n",
    "$$\n",
    "\n",
    "That is, there is a oscillatory component (governed by the magnitude of the imaginary part of $\\lambda$) bounded by an exponential envelope.\n",
    "\n",
    "Now consider applying a particular time discretisation scheme to the same test equation.\n",
    "\n",
    "### Stability regions\n",
    "\n",
    "#### Explicit Euler\n",
    "\n",
    "$$\n",
    "u(\\Delta t) = R(\\Delta t \\lambda) u_0,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "R(z) = 1 + z.\n",
    "$$\n",
    "\n",
    "Repeated application of the timestepping scheme results in\n",
    "\n",
    "$$\n",
    "u_m := u(m\\Delta t) = R(z)^m u_0.\n",
    "$$\n",
    "\n",
    "$u_m$ is therefore only bounded in the set\n",
    "\n",
    "$$\n",
    "S = \\{z \\in \\mathbb{C} \\colon |R(z)| \\le 1\\}.\n",
    "$$\n",
    "\n",
    "#### Implicit Euler\n",
    "\n",
    "We can perform the same calculation here to obtain\n",
    "\n",
    "$$\n",
    "R(z) = \\frac{1}{1 - z}\n",
    "$$\n",
    "\n",
    "#### Implicit midpoint\n",
    "\n",
    "This time we obtain\n",
    "$$\n",
    "R(z) = \\frac{1 + z/2}{1 - z/2}.\n",
    "$$\n",
    "\n",
    "#### Stability plots\n",
    "\n",
    "**Definition**: $R(z)$ is called the *stability function*, and the set $S$ is the *stability domain*.\n",
    "\n",
    "We can graphically display the stability region by plotting $|R(z)|$ in the complex plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stability(x, y, R, label):\n",
    "    pyplot.figure()\n",
    "    C = pyplot.contourf(x, y, numpy.abs(R), numpy.linspace(0, 1, 10), cmap=pyplot.cm.coolwarm)\n",
    "    \n",
    "    pyplot.colorbar(C, ticks=numpy.linspace(0, 1, 10))\n",
    "    pyplot.contour(x, y, numpy.abs(Rz), numpy.linspace(0, 1,4), colors='k')\n",
    "    pyplot.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = numpy.linspace(-3, 3)\n",
    "x, y = numpy.meshgrid(x, x)\n",
    "z = x + 1j*y\n",
    "\n",
    "Rs = [(\"Forward Euler\", 1 + z),\n",
    "      (\"Backward Euler\", 1/(1 - z)),\n",
    "      (\"Implicit Midpoint\", (1 + z/2)/(1 - z/2))]\n",
    "\n",
    "for label, Rz in Rs:\n",
    "    plot_stability(x, y, Rz, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "While the physical equation is stable and remains bounded whenever $\\operatorname{Re} \\lambda \\le 0$, the same is not true for all the methods. Explicit Euler is only stable in a disc of radius 1 centred around -1. Implicit Euler is stable _even_ in regions where the original equation is not, and tends to damp oscillations too agressively. Implicit midpoint has a stability region that exactly includes the left half plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The $\\theta$ method\n",
    "\n",
    "All of these schemes are particular examples of the (implicit) $\\theta$ method\n",
    "\n",
    "$$\n",
    "u(t + \\Delta t) = u(t) + \\Delta t f(t + \\theta \\Delta t, \\theta u(t + \\Delta t) + (1 - \\theta)u(t)).\n",
    "$$\n",
    "\n",
    "With $\\theta = 0$ we recover explicit Euler, $\\theta = 1$ produces implicit Euler, and $\\theta = 1/2$ produces implicit midpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_theta_linear(A, u0, rhsfunc, T=1, dt=0.1, theta=.5):\n",
    "    u = u0.copy()\n",
    "    t = 0\n",
    "    hist = [(t,u0)]\n",
    "    try:\n",
    "        I = numpy.eye(len(A))\n",
    "    except TypeError:\n",
    "        I = numpy.eye(1)\n",
    "    while t < T:\n",
    "        dt = min(dt, T - t)\n",
    "        rhs = (I + (1-theta)*dt*A) @ u + dt*rhsfunc(t+theta*dt)\n",
    "        u = numpy.linalg.solve(I - theta*dt*A, rhs)\n",
    "        t += dt\n",
    "        hist.append((t, u.copy()))\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = f(k=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.5\n",
    "u0 = numpy.array([.2])\n",
    "hist = ode_theta_linear(-test.k, u0,\n",
    "                        lambda t: test.k*numpy.cos(t),\n",
    "                        dt=.1, T=6, theta=theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure()\n",
    "hist = numpy.array(hist)\n",
    "pyplot.plot(hist[:,0], hist[:,1], 'o', linestyle=\"solid\", label=r\"$\\theta = {}$\".format(theta))\n",
    "tt = numpy.linspace(0, 6, 200)\n",
    "pyplot.plot(tt, test.exact(tt, u0), label=\"Exact\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations and questions\n",
    "\n",
    "With $\\theta = 1/2$ the method converges, but oscillates about the exact solution (eventually matching it if we run for long enough).\n",
    "\n",
    "What happens for $\\theta < 1/2$, what about $\\theta > 1/2$?\n",
    "\n",
    "\n",
    "### Definitions\n",
    "\n",
    "#### A-stability\n",
    "\n",
    "A method is _A-stable_ if the stability domain\n",
    "\n",
    "$$\n",
    "S = \\{z \\in \\mathbb{C} \\colon |R(z)| \\le 1\\}\n",
    "$$\n",
    "\n",
    "contains the _entire_ left half plane\n",
    "\n",
    "$$\n",
    "\\operatorname{Re} z \\le 0.\n",
    "$$\n",
    "\n",
    "This means that we can take arbitrarily large timesteps ($\\Delta t \\to \\infty$) without the method becoming unstable (diverging) for any problem that is physically stable.\n",
    "\n",
    "#### L-stability\n",
    "\n",
    "A-stability might not be enough for accurate solutions to a problem, especially if it is oscillatory (as we see above). A stronger condition is therefore sometimes used.\n",
    "\n",
    "A method is _L-stable_ if, in addition to being A-stable we also have\n",
    "\n",
    "$$\n",
    "\\lim_{z \\to \\infty} R(z) = 0.\n",
    "$$\n",
    "\n",
    "#### Questions\n",
    "\n",
    "1. For what values of $\\theta$ is the $\\theta$ method A-stable?\n",
    "2. For what values is it L-stable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the methods\n",
    "\n",
    "The formal accuracy of the method can be measured in terms of how fast the numerical solution approaches the exact solution in some norm.\n",
    "\n",
    "We say a method is of order $p$ if\n",
    "\n",
    "$$\n",
    "\\lim_{\\Delta t \\to 0} \\| u - u^* \\| \\le C (\\Delta t)^{p}\n",
    "$$\n",
    "\n",
    "for some constant $C$ independent of $\\Delta t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
