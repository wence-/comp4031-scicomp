{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on finite differences\n",
    "\n",
    "First a brief revision on vector spaces and norms.\n",
    "\n",
    "## Vector spaces\n",
    "\n",
    "A real *vector space* $V$ is a set endowed with two operations\n",
    "\n",
    "1. *addition*: $(x, y) \\in V \\times V \\to (x + y) \\in V$\n",
    "2. *scalar multiplication*: $(\\alpha, x) \\in \\mathbb{R} \\times V \\to \\alpha x \\in V$\n",
    "\n",
    "that obey the following axioms\n",
    "\n",
    "1. associativity of addition: $x + (y + z) = (x + y) + z \\text{ for all } x, y, z \\in V$;\n",
    "2. commutativity of addition: $x + y = y + x \\text{ for all } x, y \\in V$;\n",
    "3. identity for addition: $\\text{there exists } 0 \\in V \\text{ such that } x + 0 = x \\text{ for all } x \\in V$;\n",
    "4. additive inverse: $\\text{there exists an element } -x \\in V \\text{ such that }x + (-x) = 0 \\text{ for all } x \\in V$;\n",
    "5. compatibility: $\\alpha(\\beta x) = (\\alpha\\beta)x \\text{ for all } \\alpha, \\beta \\in \\mathbb{R}, x \\in V$;\n",
    "6. Identity for multiplication: $\\text{there exists } 1 \\in \\mathbb{R} \\text{ such that } 1 x = x \\text{ for all } x \\in V$;\n",
    "7. Distribution of multiplication over addition: $a(x + y) = ax + ay$;\n",
    "8. Distribution of addition over multiplication: $(a + b)x = ax + bx$;\n",
    "\n",
    "This is a rather abstract definition, the familiar example is just Euclidean vectors in $\\mathbb{R}^n$ (which is a vector space). In this case, addition is pointwise addition of components, and multiplication is multiplication of all components by a scalar.\n",
    "\n",
    "As another example, the set $\\operatorname{span} \\{1, x, x^2\\}$ of polynomials is a vector space where addition is the familiar addition, and multiplication is the familiar multiplication.\n",
    "\n",
    "## Norms on vector spaces\n",
    "\n",
    "A *norm* on a vector space $V$ is any mapping $\\|\\cdot\\| : V \\to \\mathbb{R}$ that satisfies\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\|x \\| &\\ge 0 && \\text{for all } x \\in V \\text{ and } \\|x\\| = 0 \\text{ if and only if } x = 0\\\\\n",
    "\\|\\alpha x\\| &= |\\alpha|\\|x\\| && \\text{for all } \\alpha \\in \\mathbb{R}, x \\in V\\\\\n",
    "\\|x + y\\| &\\le \\|x\\| + \\|y\\| && \\text{for all } x, y \\in V.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Again, this is a rather abstract definition, it formalises an idea of distance. Thinking of our Euclidean space with $x \\in \\mathbb{R}^n$, the norm we are perhaps most familiar with is the 2-norm\n",
    "\n",
    "\n",
    "$$\n",
    "\\| x \\|_2 = \\sqrt{\\sum_i^n |x_i|^2}.\n",
    "$$\n",
    "\n",
    "This measure the distance in a straight line between two points in $\\mathbb{R}^n$. The 1-norm (sometimes called the Manhattan norm) measures the distance if I can only walk along the unit vectors\n",
    "\n",
    "$$\n",
    "\\|x\\|_1 = \\sum_i^n |x_i|.\n",
    "$$\n",
    "\n",
    "The $\\infty$-norm (or max-norm) measures the maximum distance between the projection onto each of the unit vectors in turn\n",
    "\n",
    "$$\n",
    "\\|x\\|_\\infty = \\max_{0 < i \\le n} |x_i|.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "def plot_norm_ball(p):\n",
    "    x = numpy.linspace(-3, 3, 101)\n",
    "    x, y = numpy.meshgrid(x, x)\n",
    "    z = numpy.dstack([x, y])\n",
    "    if p == \"inf\":\n",
    "        p = r\"\\infty\"\n",
    "        z = numpy.linalg.norm(z, numpy.inf, axis=2)\n",
    "    else:\n",
    "        z = numpy.linalg.norm(z, p, axis=2)\n",
    "    pyplot.figure()\n",
    "    C = pyplot.contourf(x, y, z, numpy.linspace(0, 1, 2), cmap=pyplot.cm.coolwarm)\n",
    "    \n",
    "    pyplot.contour(x, y, z, numpy.linspace(0, 1, 2), colors='k')\n",
    "    pyplot.xlabel(\"x\")\n",
    "    pyplot.ylabel(\"y\")\n",
    "    pyplot.title(f\"Unit ball in ${p}$-norm\")\n",
    "    pyplot.gca().set_aspect(\"equal\")\n",
    "    return pyplot.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for p in [1, 2, 4, \"inf\"]:\n",
    "    plot_norm_ball(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unit ball for the 4-norm was advocated by [Piet Hein](https://en.wikipedia.org/wiki/Piet_Hein_(scientist)) as a pleasing shape for things like coffee tables and buildings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix representation of operators\n",
    "\n",
    "We saw briefly that we can represent finite difference operators as matrices. Let's look at this in a bit more detail.\n",
    "\n",
    "To do this, we need to provide an ordering of all of the degrees of freedom (dofs) in our finite difference discretisation. In one dimension, we order the points in the domain from left to right and use a single index:\n",
    "\n",
    "$$\n",
    "x_0 < x_1 < \\dots < x_{n-1}\n",
    "$$\n",
    "\n",
    "and so we have a single index for all the points $i = [0, 1, \\dots, n-1]$. We can therefore represent our function $u(x)$ discretised at the points $\\{x_i\\}$ as a vector in $\\mathbb{R}^n$\n",
    "\n",
    "$$\n",
    "U = \\begin{bmatrix} u_0 \\\\ u_1 \\\\ \\vdots \\\\ u_{n-1} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and similarly with the right hand side $f(x)$. The differencing operators *combine* entries from $U$ linearly to produce a new vector $D U$. Since this operation is linear, we can represent it as a matrix\n",
    "\n",
    "$$\n",
    "D : \\mathbb{R}^n \\to \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "which takes in a vector $U$ and spits out a new vector representing the action of the differencing operator on $U$.\n",
    "\n",
    "For example, the left-looking operator $D_- u_i = \\frac{u_i - u_{i-1}}{h}$ uses, at each point $i$ values from points $i$ and $i-1$. On a grid with 4 points, this can be represented as the matrix\n",
    "\n",
    "$$\n",
    "D_- = \\frac{1}{h}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0\\\\\n",
    "-1 & 1 & 0 & 0\\\\\n",
    "0 & -1 & 1 & 0\\\\\n",
    "0 & 0 & -1 & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Similarly, the centered difference approximation of $\\frac{\\text{d}^2}{\\text{d} x^2}$, $D^2 u_i = \\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2}$ can be written\n",
    "\n",
    "$$\n",
    "D^2 = \\frac{1}{h^2}\n",
    "\\begin{bmatrix}\n",
    "-2 & 1 & 0 & 0\\\\\n",
    "1 & -2 & 1 & 0\\\\\n",
    "0 & 1 & -2 & 1\\\\\n",
    "0 & 0 & 1 & -2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "### \"Matrix-free\" implementation\n",
    "\n",
    "If we only never need to apply the differencing operator, it might make sense (memory or efficiency, for example) to just provide a function which computes the matrix-vector multiplication without storing the matrix. Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy\n",
    "\n",
    "def dminus(u, h):\n",
    "    n, = u.shape\n",
    "    du = numpy.zeros_like(u)\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            du[i] = 1/h * u[i]\n",
    "        else:\n",
    "            du[i] = 1/h * (u[i] - u[i-1])\n",
    "    return du\n",
    "\n",
    "def dminusop(u, h):\n",
    "    n, = u.shape\n",
    "    D = numpy.eye(n) - numpy.diag(numpy.full(n-1, 1), k=-1)\n",
    "    D *= 1/h\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "u = numpy.random.rand(n)\n",
    "h = 1/n\n",
    "dminus(u, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = dminusop(u, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D @ u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D finite differences\n",
    "### Indexing matrix representation in 2D\n",
    "### Sparse matrices\n",
    "\n",
    "## CFL conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
