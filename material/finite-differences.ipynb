{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial discretisation\n",
    "\n",
    "So far, we've seen time derivatives and ordinary differential equations of the form\n",
    "\n",
    "$$\n",
    "\\dot{u} = f(t, u).\n",
    "$$\n",
    "\n",
    "Most problems one encounters in the real world have spatial as well as time derivatives. Our first example is the [*Poisson equation*](https://en.wikipedia.org/wiki/Poisson%27s_equation):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "-\\frac{\\text{d}^2 u}{\\text{d} x^2} &= f(x) \\quad x \\in \\Omega = (-1, 1)\\\\\n",
    " u(-1) &= a\\\\\n",
    " \\left.\\frac{\\text{d} u}{\\text{d} x}\\right|_1 &= b\\\\\n",
    " \\end{align}.\n",
    "$$\n",
    "\n",
    "This is termed a *boundary value problem* (BVP), as opposed to the ODEs which were *initial value problems*, since we do not specify an initial condition, but rather a condition on the boundary of the domain.\n",
    "\n",
    "This equation appears in a remarkably large number of places. As one example, it models the equilibrium temperature profile of a thermally conducting material maintained at constant temperatures $a$ and $b$ at either end.\n",
    "\n",
    "To solve this problem numerically we must make a number of choices:\n",
    "\n",
    "- how to represent the solution $u$;\n",
    "- how to compute its derivatives;\n",
    "- how to enforce the boundary conditions;\n",
    "- how and where to evaluate $f$;\n",
    "- in what sense we would like our solution to satisfy the equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite difference framework\n",
    "\n",
    "We will focus on _finite difference_ methods here, which make the following choices in answer to the questions above:\n",
    "\n",
    "- The solution $u(x)$ is represented by _pointwise_ values $u_i = u(x_i)$ at some discrete set of points $-1 = x_0 < x_1 < \\dots < x_N = 1$. Importantly, the framework _does not_ specify the value of $u$ outside of these points;\n",
    "- derivatives of $u$ at points $x_i$ are approximated using differencing formulae that utilise a finite number of neighbouring points (independent of $N$);\n",
    "- boundary conditions are either enforced pointwise (e.g. the $u(-1)$ case above), or (when constraining derivatives) with one-sided differencing formulae;\n",
    "- $f$ is evaluated pointwise at each $x_i$;\n",
    "- we require that our finite difference method satisfies the equation pointwise at each $x_i$ in the interior of the domain.\n",
    "\n",
    "### Differencing formulae\n",
    "\n",
    "Our starting point is the definition of a derivative:\n",
    "\n",
    "$$\n",
    "\\frac{d u(x)}{d x} = \\lim_{\\epsilon \\to 0} \\frac{u(x + \\epsilon) - u(x)}{\\epsilon}.\n",
    "$$\n",
    "\n",
    "If we wish to approximate this in our finite difference framework, where we only have point values, we can do so using neighbouring values. Writing $x_{i+1} - x_i = h$ for convenience, we can write\n",
    "\n",
    "$$\n",
    "\\frac{d u(x_i)}{d x} \\approx \\frac{u(x_{i+1}) - u(x_i)}{h} = \\frac{u_{i+1} - u_i}{h} =: D_+ u_i.\n",
    "$$\n",
    "\n",
    "This is a _one-sided_ approximation: we only use $u_i$ and $u_{i+1}$. Another one-sided approximation would be to offset in the other direction\n",
    "\n",
    "$$\n",
    "D_{-} u_i := \\frac{u_i - u_{i-1}}{h}.\n",
    "$$\n",
    "\n",
    "Finally, we can also use a _centred_ approximation by averaging the two one-sided approximations:\n",
    "\n",
    "$$\n",
    "D_0 u_i := \\frac{u_{i+1} - u_{i-1}}{2h} = \\frac{1}{2} (D_+ + D_-) u_i.\n",
    "$$\n",
    "\n",
    "Let's have a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.lines as mlines\n",
    "pyplot.style.use('ggplot')\n",
    "\n",
    "n = 200\n",
    "h = 2/(n-1)\n",
    "x = numpy.linspace(1,2.5,n)\n",
    "pyplot.plot(x, numpy.sin(x));\n",
    "\n",
    "def newline(p1, p2, **kwargs):\n",
    "    ax = pyplot.gca()\n",
    "    xmin, xmax = ax.get_xbound()\n",
    "\n",
    "    if(p2[0] == p1[0]):\n",
    "        xmin = xmax = p1[0]\n",
    "        ymin, ymax = ax.get_ybound()\n",
    "    else:\n",
    "        ymax = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmax-p1[0])\n",
    "        ymin = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmin-p1[0])\n",
    "\n",
    "    l = mlines.Line2D([xmin,xmax], [ymin,ymax], **kwargs)\n",
    "    ax.add_line(l)\n",
    "    return l\n",
    "\n",
    "h = 0.25\n",
    "xi = 1.6\n",
    "ximinus = xi - h\n",
    "xiplus = xi + h\n",
    "\n",
    "pyplot.plot([ximinus, xi, xiplus], numpy.sin([ximinus, xi, xiplus]), marker=\"o\", linestyle=\"none\")\n",
    "\n",
    "newline((xi, numpy.sin(xi)), (xiplus, numpy.sin(xiplus)), linestyle=\"dashed\", label=\"$D_+ u(x)$\")\n",
    "newline((xi, numpy.sin(xi)), (ximinus, numpy.sin(ximinus)), linestyle=\"dotted\", label=\"$D_- u(x)$\")\n",
    "newline((ximinus, numpy.sin(ximinus)), (xiplus, numpy.sin(xiplus)), linestyle=\"-.\", label=\"$D_0 u(x)$\")\n",
    "\n",
    "\n",
    "newline((xi, numpy.sin(xi)), (xiplus, numpy.sin(xi) + h*numpy.cos(xi)), color=\"black\", label=\"$u'(x)$\")\n",
    "\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the full approximate derivative too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "h = 2/(n-1)\n",
    "x = numpy.linspace(-1,1,n)\n",
    "u = numpy.sin(x)\n",
    "pyplot.figure()\n",
    "pyplot.plot(x, numpy.cos(x), label=\"$u'$\");\n",
    "pyplot.plot(x[:-1], (u[1:] - u[:-1])/h, label=\"$D_+$\", marker=\"o\", linestyle=\"none\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Certainly from the picture of the slope above, it appears that the centered difference formula is more accurate than the one-sided approximations. Can we formalise this at all?\n",
    "\n",
    "To do so, we turn to the favourite tool of the budding numericist, the *taylor expansion*.\n",
    "\n",
    "### Recap, Taylor expansions\n",
    "\n",
    "For a sufficiently smooth function $u$, given a point $x$, we can represent the function at a new point $x + h$ by its Taylor expansion\n",
    "\n",
    "$$\n",
    "u(x + h) = u(x) + u'(x) h + \\frac{1}{2} u''(x) h^2 + \\frac{1}{6} u'''(x) h^3 + \\dots = \\sum_{n=0}^\\infty \\frac{1}{n!} h^n u^{(n)}(x) \n",
    "$$\n",
    "\n",
    "where the notation $u'$ is shorthand for $\\frac{\\text{d} u}{\\text{d} x}$ and $u^{(n)}(x) = \\frac{\\text{d}^n u}{\\text{d} x^n}$.\n",
    "\n",
    "If we chop off the series at some finite $n$ we write\n",
    "\n",
    "$$\n",
    "u(x + h) = u(x) + u'(x) h + \\frac{1}{2} u''(x) h^2 + \\mathcal{O}(h^3)\n",
    "$$\n",
    "\n",
    "with $h$ sufficiently small.\n",
    "\n",
    "To determine the order of a method, we substitute the Taylor expansion into the differencing expression and calculate.\n",
    "\n",
    "As an example, let us consider the one-sided differencing operator $D_+$. To simplify notation, we will choose $x = 0$, and we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "u'(0) &\\approx \\frac{u(h) - u(0)}{h} \\quad \\text{ definition of } D_+\\\\\n",
    "      &= h^{-1}(\\underbrace{u(0) + u'(0) h + \\frac{1}{2} u''(0) h^2 + \\mathcal{O}(h^3)}_{u(h)} - u(0)) \\\\\n",
    "      &= u'(0) + \\frac{1}{2} u''(0) h + \\mathcal{O}(h^2)\\\\\n",
    "\\end{align}.\n",
    "$$\n",
    "\n",
    "The leading-order error term in the right hand side is $\\mathcal{O}(h)$, and so we say that this is a _first-order_ method. Derivation that the operator $D_-$ is also first-order proceeds identically.\n",
    "\n",
    "#### Questions\n",
    "\n",
    "1. Show that the centered difference operator $D_0$ computes a second-order accurate derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability\n",
    "\n",
    "We will postpone mathematical discussion of stability for a while, and give an intuition for some potential problems. Let us first check that our implementation of differencing operators provides us with the expected (mathematical) convergence orders for a smooth function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dplus(x, u):\n",
    "    return x[:-1], (u[1:] - u[:-1])/(x[1:] - x[:-1])\n",
    "\n",
    "def dminus(x, u):\n",
    "    return x[1:], (u[1:] - u[:-1])/(x[1:] - x[:-1])\n",
    "\n",
    "def center(x, u):\n",
    "    return x[1:-1], (u[2:] - u[:-2])/(x[2:] - x[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = 2**numpy.arange(3, 10)\n",
    "\n",
    "def error(f, df, op):\n",
    "    for n in grids:\n",
    "        x = numpy.linspace(-1, 1, n)\n",
    "        x, y = op(x, f(x))\n",
    "        yield numpy.linalg.norm(y - df(x), numpy.inf)\n",
    "\n",
    "pyplot.figure()\n",
    "for op in [dplus, dminus, center]:\n",
    "    pyplot.loglog(1/grids, list(error(numpy.sin, numpy.cos, op)), marker=\"o\", linestyle=\"none\", label=op.__name__)\n",
    "    \n",
    "pyplot.xlabel(\"Resolution ($h$)\")\n",
    "pyplot.ylabel(\"$l_\\infty$ error in derivative\")\n",
    "\n",
    "pyplot.loglog(1/grids, 1/grids, label=\"$h$\")\n",
    "pyplot.loglog(1/grids, 1/grids**2, label=\"$h^2$\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So both the one-sided differences are first-order accurate, whereas the centered difference is second-order accurate, as expected. One thing to be wary of, however, is using some of these approximations for functions that are \"rough\" on the grid scale.\n",
    "\n",
    "We can make this question more precise by asking whether there are functions whose derivatives are non-zero, but for which our numerical approximations compute $u'(x_i) = 0$.\n",
    "\n",
    "Let's try and contrive an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.linspace(-1, 1, 9)\n",
    "xf = numpy.linspace(-1, 1, 100)\n",
    "\n",
    "def f(x):\n",
    "    return numpy.cos(1/2 + 4*numpy.pi*x)\n",
    "\n",
    "def df(x):\n",
    "    return -4*numpy.pi*numpy.sin(1/2 + 4*numpy.pi*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyplot.figure()\n",
    "pyplot.plot(x, f(x), marker=\"o\", label=\"coarse\")\n",
    "pyplot.plot(xf, f(xf), \"-\", label=\"fine\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the derivatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure()\n",
    "for op in [dplus, dminus, center]:\n",
    "    x_, y = op(x, f(x))\n",
    "    pyplot.plot(x_, y, \"o-\", label=op.__name__)\n",
    "pyplot.plot(xf, df(xf), \"-\", label=\"Exact\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The centered difference approximation produces a _zero_ derivative for this function. Hence if we have a solution $u(x)$, we can (at least to the numerical operator) construct a new solution $\\tilde{u}(x) = u(x) + f(x)$.\n",
    "\n",
    "Suddenly, even if our actual equation has a unique solution, the numerical solution is no longer unique. This turns out to cause all kinds of terrible issues with numerical algorithms and must be avoided at all costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
