{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-dependent PDEs\n",
    "\n",
    "So far we've seen ODEs, and looked at time-integration techniques, and then PDEs but we mostly focused on stationary problems. Now we will combine the two and look at time-dependent PDEs. As a model problem we will consider the [*heat equation*](https://en.wikipedia.org/wiki/Heat_equation) which models the diffusion of heat in a material with some given thermal conductivity\n",
    "\n",
    "$$\n",
    "\\partial_t u - \\alpha \\nabla^2 u = 0\n",
    "$$\n",
    "\n",
    "augmented with appropriate initial and boundary conditions. We will look at both implicit and explicit time integration schemes for this equation, starting with explicit schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "pyplot.style.use('ggplot')\n",
    "from collections import namedtuple\n",
    "Point = namedtuple(\"Point\", (\"x\", \"y\"))\n",
    "\n",
    "class Grid(object):\n",
    "    def __init__(self, Nx, Ny, P0=Point(0,0), P1=Point(1,1)):\n",
    "        X0, Y0 = P0\n",
    "        X1, Y1 = P1\n",
    "        self.W = X1 - X0\n",
    "        self.H = Y1 - Y0\n",
    "        self.Nx = Nx\n",
    "        self.Ny = Ny\n",
    "        x = numpy.linspace(X0, X1, self.Nx)\n",
    "        y = numpy.linspace(Y0, Y1, self.Ny)\n",
    "        self.XY = numpy.meshgrid(x, y, indexing=\"ij\")\n",
    "    \n",
    "    @property\n",
    "    def ndof(self):\n",
    "        return self.Nx*self.Ny\n",
    "\n",
    "    @property\n",
    "    def hx(self):\n",
    "        return self.W/(self.Nx - 1)\n",
    "    \n",
    "    @property\n",
    "    def hy(self):\n",
    "        return self.H/(self.Ny - 1)\n",
    "\n",
    "    def alpha(self, i, j):\n",
    "        return i*self.Ny + j\n",
    "\n",
    "    def new_vector(self, components=1):\n",
    "        vec = numpy.zeros(self.Nx*self.Ny*components, dtype=float)\n",
    "        shape = (self.Nx, self.Ny)\n",
    "        if components > 1:\n",
    "            shape = shape + (components, )\n",
    "        return vec.reshape(shape)\n",
    "    \n",
    "    def contourf(self, u, levels=11, ax=None):\n",
    "        U = u.reshape(self.Nx, self.Ny)\n",
    "        if ax is None:\n",
    "            pyplot.figure()\n",
    "            contours = pyplot.contourf(*self.XY, U, levels)\n",
    "            pyplot.colorbar(contours)\n",
    "        else:\n",
    "            contours = ax.contourf(*self.XY, U, levels)\n",
    "            pyplot.colorbar(contours)\n",
    "        return contours\n",
    "        \n",
    "    def quiver(self, u, colour=None, ax=None):\n",
    "        U = u.reshape(self.Nx, self.Ny, 2)\n",
    "        if ax is None:\n",
    "            pyplot.figure()\n",
    "            quiver = pyplot.quiver\n",
    "        else:\n",
    "            quiver = ax.quiver\n",
    "        if colour is None:\n",
    "            vecs = quiver(*self.XY, U[..., 0], U[..., 1])\n",
    "        else:\n",
    "            vecs = quiver(*self.XY, U[..., 0], U[..., 1], colour)\n",
    "            pyplot.colorbar(vecs)\n",
    "        return vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An explicit scheme\n",
    "\n",
    "We will first discretise the time derivative. Recall the general form of an ODE is\n",
    "\n",
    "$$\n",
    "\\partial_t u = f(t, u)\n",
    "$$\n",
    "\n",
    "where here we have\n",
    "\n",
    "$$\n",
    "f(t, u) = \\alpha \\nabla^2 u.\n",
    "$$\n",
    "\n",
    "In an explicit scheme, we evaluate $f(u)$ at the beginning of the timestep. We'll start with explicit Euler\n",
    "\n",
    "$$\n",
    "u^{n+1} = u^n + \\Delta t \\alpha \\nabla^2 u^n.\n",
    "$$\n",
    "\n",
    "So given an initial condition $u^0$ we just need to be able to compute $\\alpha \\nabla^2 u^0$ and add it on to get the value at the next timestep.\n",
    "\n",
    "Let's solve this problem on the square domain $\\Omega = [0, 1] \\times [0, 1]$ with the boundary conditions\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "u &= 1 && x = 0, y \\in [0.25, 0.75]\\\\\n",
    "u &= 0 && x = 1, y \\in [0.6, 0.8]\\\\\n",
    "\\nabla u \\cdot n &= 0 && \\text{otherwise}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can think of this as modelling a 2D room with a radiator on one wall, a window on the other, and perfectly insulating (ha!) walls everywhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def f(un, f_, Nx, Ny, hx, hy, stencil):\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            f_[i, j] = 0\n",
    "            # Dirichlet boundary\n",
    "            if i == 0 and 0.25 <= j*hy <= 0.75:\n",
    "                f_[i, j] = 0\n",
    "            elif i == Nx - 1 and 0.6 <= j*hy <= 0.8:\n",
    "                f_[i, j] = 0\n",
    "            else:\n",
    "                for idx, (i_, j_) in enumerate([(i-1, j), (i, j-1), (i, j), (i, j+1), (i+1, j)]):\n",
    "                    # Homogeneous Neumann everywhere else: i-1 -> i+1 (i = 0), i+1 -> i-1 (i = Nx - 1), etc...\n",
    "                    i_ = (Nx - 1) - abs(Nx - 1 - abs(i_))\n",
    "                    j_ = (Ny - 1) - abs(Ny - 1 - abs(j_))\n",
    "                    f_[i, j] += stencil[idx] * un[i_, j_]\n",
    "    return f_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how on the Dirichlet boundary, we set the update function to return zero. This way, as long as our initial condition satisfies the boundary conditions, it will do so for all time. For the homogeneous Neumann condition, we implement the symmetric \"reflected\" condition (rather than a one-sided difference).\n",
    "\n",
    "Let's go ahead and integrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(N):\n",
    "    grid = Grid(N, N)\n",
    "    u = grid.new_vector()\n",
    "    # Initial condition, 1 on the right boundary when y \\in [0.25, 0.75]\n",
    "    for j in range(grid.Ny):\n",
    "        if 0.25 <= j*grid.hy <= 0.75:\n",
    "            u[0, j] = 1      \n",
    "    return grid, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def explicit_euler(u0, dt, grid, alpha=1, T=5):\n",
    "    us = [u0]\n",
    "    ts = [0]\n",
    "    update = numpy.zeros_like(u0)\n",
    "    u = u0\n",
    "    t = 0\n",
    "    # Notice how the sign is flipped relative to -\\nabla^2 (since we have \\partial_t u = +\\nabla^2 u)\n",
    "    stencilx = 1/grid.hx**2 * numpy.array([1, 0, -2, 0, 1])\n",
    "    stencily = 1/grid.hy**2 * numpy.array([0, 1, -2, 1, 0])\n",
    "    stencil = stencilx + stencily    \n",
    "    while t < T:\n",
    "        update = f(u, update, grid.Nx, grid.Ny, grid.hx, grid.hy, stencil)\n",
    "        if numpy.linalg.norm(update, numpy.inf) < 1e-10:\n",
    "            # Terminate if we've reached a steady-state\n",
    "            break\n",
    "        # Explicit Euler: u <- u + dt f(u)\n",
    "        u = u + dt*alpha*update\n",
    "        us.append(u)\n",
    "        t += dt\n",
    "        ts.append(t)\n",
    "    return ts, us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to integrate the equation, let's try on a relatively coarse grid.;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 11\n",
    "alpha = 1\n",
    "grid, u = setup(N)\n",
    "dt = 0.00252\n",
    "ts, us = explicit_euler(u, dt, grid, alpha=alpha, T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.contourf(us[-1], levels=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like the solution I'm expecting, but the timestep is *very* small. I only have 10 cells in each direction.\n",
    "\n",
    "Let's see what happens when we make the timestep bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 11\n",
    "alpha = 1\n",
    "grid, u = setup(N)\n",
    "dt = 0.00255\n",
    "ts, us = explicit_euler(u, dt, grid, alpha=alpha, T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.contourf(us[-1], levels=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instability for large timesteps\n",
    "\n",
    "Uh-oh, this looks bad. What's going on? We have hit the [CFL](https://en.wikipedia.org/wiki/Courant–Friedrichs–Lewy_condition) constraint for this PDE.\n",
    "\n",
    "This property of a timestepping scheme, named after three mathematicians, Courant, Friedrichs, and Lewy, provides us with a rule for determining an appropriate maximum timestep given a particular spatial discretisation. An intuition for what is going on is that the *physical* equation has some domain of dependence. A region of the solution at time $t$ affects some other region of the solution at $t + \\Delta t$. If our numerical scheme fails to capture this dependence, we get bad behaviour.\n",
    "\n",
    "In other words, if we pick a timestep that is too large, information can propagate \"too fast\" in our numerical simulation.\n",
    "\n",
    "The CFL condition was developed in the analysis of advection equations\n",
    "\n",
    "$$\n",
    "\\partial_t u - w \\cdot \\nabla u = 0.\n",
    "$$\n",
    "\n",
    "For which we have the constraint (with $w = 1$)\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta t}{\\Delta x} \\le 1.\n",
    "$$\n",
    "\n",
    "That is, I can't push information more than a single cell in one timestep.\n",
    "\n",
    "For the heat equation, the restriction is much tighter, we need\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta t}{(\\Delta x)^2} \\le c\n",
    "$$\n",
    "\n",
    "with $c$ some (dimension-dependent) constant. In two dimensions, for explicit Euler, we have $c = 0.25$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalue analysis\n",
    "\n",
    "How did I arrive at this magic constant? Recall that the *stability region* for explicit Euler is the unit circle centred at -1 in the complex plane. A necessary condition for stability of the timestepping scheme applied to the scalar Dahlquist test equation\n",
    "\n",
    "$$\n",
    "\\partial_t u = \\lambda u\n",
    "$$\n",
    "\n",
    "which, discretised with explicit Euler gives\n",
    "\n",
    "$$\n",
    "u^{n+1} = u^n + \\lambda\\Delta t u^n,\n",
    "$$\n",
    "\n",
    "is that $-2 \\le \\lambda \\Delta t < 0$.\n",
    "\n",
    "How can we apply this same idea here, when we have\n",
    "\n",
    "$$\n",
    "\\partial_t u = \\nabla^2 u\n",
    "$$\n",
    "\n",
    "or, discretised\n",
    "\n",
    "$$\n",
    "u^{n+1} = u^n + \\Delta t \\nabla^2 u^n?\n",
    "$$\n",
    "\n",
    "For this operator, we can find the bound by considering the *eigenvalues* of $\\nabla^2$. If we can find them, we can replace the discretised operator by a diagonal one (with the eigenvalues on the diagonal), and then treat each equation separately.\n",
    "\n",
    "Let's go ahead and discretise $\\nabla^2$ and look at the eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(grid):\n",
    "    ndof = grid.ndof\n",
    "    A = numpy.zeros((ndof, ndof))\n",
    "    X, Y = grid.XY\n",
    "    Nx = grid.Nx\n",
    "    Ny = grid.Ny\n",
    "    stencilx = 1/grid.hx**2 * numpy.array([1, 0, -2, 0, 1])\n",
    "    stencily = 1/grid.hy**2 * numpy.array([0, 1, -2, 1, 0])\n",
    "    stencil = stencilx + stencily\n",
    "    for i in range(grid.Nx):\n",
    "        for j in range(grid.Ny):\n",
    "            row = grid.alpha(i, j)\n",
    "            # Dirichlet boundary\n",
    "            if i == 0 and 0.25 <= j*grid.hy <= 0.75:\n",
    "                A[row, row] = 0\n",
    "            elif i == grid.Nx - 1 and 0.6 <= j*grid.hy <= 0.8:\n",
    "                A[row, row] = 0\n",
    "            else:\n",
    "                indices = [(i-1, j), (i, j-1), (i, j), (i, j+1), (i+1, j)]\n",
    "                i_ = lambda i_: (Nx - 1) - abs(Nx - 1 - abs(i_))\n",
    "                j_ = lambda j_: (Ny - 1) - abs(Ny - 1 - abs(j_))\n",
    "                cols = [grid.alpha(i_(i), j_(j)) for i, j in indices]\n",
    "                for c, s in zip(cols, stencil):\n",
    "                    A[row, c] += s\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(11, 11)\n",
    "A = laplacian(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in the *smallest* (most negative) eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = numpy.linalg.eigvals(A)\n",
    "evals.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need, when multiplying this by $\\Delta t$ to arrive at a number larger than -2. Which implies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = -2/evals.min()\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $\\Delta t = 0.0025$ is right on the edge of stability for our method (hence the problem blowing up with $\\Delta t = 0.0026$).\n",
    "\n",
    "What is the relationship we need between $\\Delta x$ and $\\Delta t$? The most negative eigenvalue scales with $\\frac{1}{(\\Delta x)^2}$, and so we need\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta t}{(\\Delta x)^2} = \\text{const}.\n",
    "$$\n",
    "\n",
    "Each time we double the spatial resolution we must reduce the timestep by a factor of four!\n",
    "\n",
    "### Bounding the eigenvalues of a regular stencil\n",
    "\n",
    "For the stencils we see in the course, we can put a bound on the eigenvalues (and in particular the smallest one) using a remarkable theorem due to [Gershgorin](https://en.wikipedia.org/wiki/Gershgorin_circle_theorem).\n",
    "\n",
    "For *any* square matrix $A$ with entries $a_{ij}$, write\n",
    "\n",
    "$$\n",
    "R_i = \\sum_{j \\ne i} |a_{ij}|\n",
    "$$\n",
    "\n",
    "(the sum of the absolute value of the off-diagonal entries), and define the disc\n",
    "\n",
    "$$\n",
    "D(a_{ii}, R_i) = \\{z \\in \\mathbb{C} : |z - a_{ii}| \\le R_i\\}\n",
    "$$\n",
    "\n",
    "(that is, a circle centered at $a_{ii}$ with radius $R_i$).\n",
    "\n",
    "Then every eigenvalue of $A$ is contained in at least one of these discs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "def gershgorin(A):\n",
    "    n = len(A)\n",
    "    evals = numpy.linalg.eigvals(A)\n",
    "    patches = []\n",
    "    # draw discs\n",
    "    seen = set()\n",
    "    for i in range(n):\n",
    "        xi = numpy.real(A[i,i])\n",
    "        yi = numpy.imag(A[i,i])\n",
    "        ri = numpy.sum(numpy.abs(A[i,:])) - numpy.abs(A[i,i]) \n",
    "        if (xi, yi, ri) in seen:\n",
    "            continue\n",
    "        circle = Circle((xi, yi), ri)\n",
    "        patches.append(circle)\n",
    "        seen.add((xi, yi, ri))\n",
    "    fig, ax = pyplot.subplots()\n",
    "    p = PatchCollection(patches, alpha=0.1)\n",
    "    ax.add_collection(p)\n",
    "    pyplot.plot(numpy.real(evals), numpy.imag(evals),' o')\n",
    "    pyplot.axis('equal')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gershgorin(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this isn't a very good estimate of many of the eigenvalues, but it's quite good for the minimal one.\n",
    "\n",
    "So, if I give you a stencil\n",
    "\n",
    "$$\n",
    "\\frac{1}{h_x^2}\\begin{bmatrix}-1 & 2 & -1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "we can immediately say that the maximal eigenvalue will be less than or equal to $\\frac{4}{h_x^2}$, and the minimal one will be greater than or equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = numpy.asarray([[5., 3., 2.], \n",
    "                         [4., 6., 5.],\n",
    "                         [-3., 1., 4.]])\n",
    "gershgorin(example);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking through the timestep restriction\n",
    "\n",
    "Our only chance of being able to take larger timesteps is to increase the size of the stability region. We can try and do so with explicit methods, but we will *always* run into the timestep constraint eventually (since no explicit method contains an unbounded stability region.\n",
    "\n",
    "Instead, we turn to *implicit* methods. We're now going to have to invert the operator at every timestep, hence our interest in different methods for doing so. We'll do implicit Euler first, for which the discretised problem looks like\n",
    "\n",
    "$$\n",
    "\\mathbb{I} u^{n+1} - \\Delta t \\nabla^2 u^{n+1} = u^n.\n",
    "$$\n",
    "\n",
    "Rearranging, we obtain\n",
    "\n",
    "$$\n",
    "u^{n+1} = (\\mathbb{I} - \\Delta t \\nabla^2)^{-1} u^n\n",
    "$$\n",
    "\n",
    "so our update step is to invert an operator onto the old state, rather than applying the operator to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "\n",
    "def implicit_euler(u0, dt, grid, alpha=1, T=5):\n",
    "    A = dt*alpha*laplacian(grid)\n",
    "    I = numpy.eye(len(A))\n",
    "    op = I - A\n",
    "    lu, piv = scipy.linalg.lu_factor(op)\n",
    "    t = 0\n",
    "    us = [u0]\n",
    "    ts = [t]\n",
    "    u = u0\n",
    "    while t < T:\n",
    "        u = scipy.linalg.lu_solve((lu, piv), u.flat).reshape(u.shape)\n",
    "        t += dt\n",
    "        us.append(u)\n",
    "        ts.append(t)\n",
    "        if numpy.linalg.norm(us[-2] - us[-1], numpy.inf) < 1e-10:\n",
    "            break\n",
    "    return ts, us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 21\n",
    "grid, u = setup(N)\n",
    "dt = 1\n",
    "ts, us = implicit_euler(u, dt, grid, T=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.contourf(us[-1], levels=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
